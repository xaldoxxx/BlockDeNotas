{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPKS/NUv64d7xCeau3wEoKY",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/xaldoxxx/BlockDeNotas/blob/main/bs4templatePOO.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "autoejercicio para practicar poo y raspado\n",
        "\n",
        "\n",
        "Beautiful Soup es una librería de Python que se utiliza para extraer y procesar datos de páginas web. Se puede utilizar en conjunción con programación orientada a objetos (POO) para crear una clase que utilice Beautiful Soup para raspar y procesar datos de una página web.\n",
        "\n",
        "\n",
        "\n",
        "A continuación, te presento un ejemplo de cómo se podría usar Beautiful Soup con POO para raspar y procesar datos de una página web:"
      ],
      "metadata": {
        "id": "CvMErt9cedTy"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "J_zjW6UieWLe"
      },
      "outputs": [],
      "source": [
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "\n",
        "class WebScraper:\n",
        "    def __init__(self, url):\n",
        "        self.url = url\n",
        "        self.page = None\n",
        "        self.soup = None\n",
        "    \n",
        "    def fetch_page(self):\n",
        "        \"\"\"Hace una petición GET a la URL y obtiene el contenido de la página\"\"\"\n",
        "        r = requests.get(self.url)\n",
        "        self.page = r.text\n",
        "    \n",
        "    def create_soup(self):\n",
        "        \"\"\"Crea un objeto Beautiful Soup a partir del contenido de la página\"\"\"\n",
        "        self.soup = BeautifulSoup(self.page, 'html.parser')\n",
        "    \n",
        "    def extract_data(self):\n",
        "        \"\"\"Extrae datos específicos de la página utilizando Beautiful Soup\"\"\"\n",
        "        # Implementa aquí la lógica de extracción de datos\n",
        "        pass\n",
        "    \n",
        "    def run(self):\n",
        "        \"\"\"Ejecuta todas las operaciones necesarias para raspar y procesar la página\"\"\"\n",
        "        self.fetch_page()\n",
        "        self.create_soup()\n",
        "        self.extract_data()\n",
        "\n",
        "# Crea una instancia de la clase WebScraper y ejecuta el proceso de raspado\n",
        "scraper = WebScraper('https://www.ejemplo.com')\n",
        "scraper.run()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "En este ejemplo, se ha creado una clase WebScraper que tiene métodos para hacer una petición GET a una URL, crear un objeto Beautiful Soup a partir del contenido de la página y extraer datos de la página utilizando Beautiful Soup. La clase también tiene un método run que ejecuta todas las operaciones necesarias para raspar y procesar la página.\n",
        "\n",
        "\n",
        "\n",
        "Para utilizar esta clase, se puede crear una instancia de WebScraper y llamar al método run. Esto realizará todas las operaciones necesarias para raspar y procesar la página especificada en la URL."
      ],
      "metadata": {
        "id": "cVKmUDklehdZ"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "nVlrZsvdek45"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}